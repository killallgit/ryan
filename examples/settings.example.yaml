logging:
    file: ./.ryan/debug.log
    preserve: false

show_thinking: true
streaming: true

ollama:
    model: qwen3:latest
    system_prompt: examples/SYSTEM_PROMPT.md
    url: https://ollama.kitty-tetra.ts.net
    poll_interval: 10
    timeout: "1h"
    use_langchain: true             # Use LangChain for enhanced agent capabilities

tools:
    enabled: true                    # Enable/disable tool calling system
    truncate_output: true           # Truncate long tool outputs in TUI
    models:                         # Models that support tool calling
    - deepseek-r1:latest
    - qwen3:latest
    - llama3.1:latest
    - qwen2.5-coder:7b
    - mistral-small:latest
    
    bash:
        enabled: true               # Enable bash command execution
        timeout: "90s"              # Maximum execution time per command
        allowed_paths: [".", "/tmp"] # Directories where commands can run
        skip_permissions: false     # Skip all safety checks (dangerous!)
        
    file_read:
        enabled: true               # Enable file reading
        max_file_size: "10MB"       # Maximum file size to read
        allowed_extensions:         # Allowed file extensions
            - ".txt"
            - ".md"
            - ".go"
            - ".json"
            - ".yaml"
            - ".yml"
            - ".py"
            - ".js"
            - ".ts"
            
    search:
        enabled: true               # Enable search functionality (future)
        timeout: "10s"              # Search operation timeout
        