# Example Ryan settings.yaml with vector store configuration

# Vector store configuration
vectorstore:
  enabled: true
  provider: chromem
  persistence_dir: ./.ryan/vectorstore
  enable_persistence: true
  
  embedder:
    provider: ollama         # ollama, openai, or mock
    model: nomic-embed-text
    base_url: http://localhost:11434
    # api_key: ""           # For OpenAI, set via OPENAI_API_KEY env var
  
  collections:
    - name: conversations
      metadata:
        type: chat_history
    - name: documents
      metadata:
        type: document_index
  
  indexer:
    chunk_size: 1000
    chunk_overlap: 200

# Rest of Ryan configuration...
show_thinking: true
streaming: true

ollama:
  url: http://localhost:11434
  model: qwen3:latest
  timeout: 90s

langchain:
  memory:
    type: vector         # Use vector memory instead of buffer
    window_size: 10
    max_tokens: 4000